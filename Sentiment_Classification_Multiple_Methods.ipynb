{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617fe2ca",
   "metadata": {},
   "source": [
    "## Using Tradition ML Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "sw = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59252e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'movies_sentiment_data.csv')\n",
    "display(df.head(1))\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a05aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = np.where(df['sentiment']=='positive',1 ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21060752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(text):\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\w+','',text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+','' ,text)\n",
    "    text = ' '.join([word for word in text.split() if word not in sw])\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_reviews'] = df['review'].apply(clean_reviews)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de91048",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_text = ' '.join(df['clean_reviews'])\n",
    "wc = WordCloud(background_color='white').generate(word_cloud_text)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(wc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d019c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_reviews']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e402b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vectorizer, classifier, X_train, y_train):\n",
    "    model = Pipeline([\n",
    "        ('vec', vectorizer),\n",
    "        ('clf', classifier)\n",
    "    ])\n",
    "\n",
    "    display(model.fit(X_train, y_train))\n",
    "    y_pred = cross_val_predict(model, X_test, y_test,cv = 5)\n",
    "    print(classification_report(y_pred, y_test))\n",
    "    print(confusion_matrix(y_pred, y_test))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = train_model(CountVectorizer(), RandomForestClassifier(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17296310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = train_model(TfidfVectorizer(), RandomForestClassifier(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = train_model(CountVectorizer(), MultinomialNB(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591015bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = train_model(TfidfVectorizer(), MultinomialNB(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4338a",
   "metadata": {},
   "source": [
    "## Using ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'movies_sentiment_data.csv')\n",
    "display(df.head(1))\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec585bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = np.where(df['sentiment']=='positive',1,0)\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(text):\n",
    "    # Remove HTML tags from the text using BeautifulSoup\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    \n",
    "    # Remove URLs (starting with http, https, or www) from the text\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses (anything that starts with '@') from the text\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters (anything other than letters, numbers, and spaces) from the text\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove any digits from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove stop words from the text (words that are common and provide little meaning)\n",
    "    # 'sw' is a predefined list of stop words\n",
    "    text = ' '.join([word for word in text.split() if word not in sw])\n",
    "    \n",
    "    # Apply stemming to reduce words to their root form (using a stemmer like PorterStemmer)\n",
    "    # 'stemmer' is a predefined stemmer object\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    # Remove extra spaces (more than one space) and strip leading/trailing spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_reviews'] = df['review'].apply(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_pad = pad_sequences(X_seq,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = keras.Sequential([\n",
    "    keras.layers.Embedding(10000, 100),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=5, restore_best_weights=True)\n",
    "\n",
    "history = ann_model.fit(X_train, y_train,\n",
    "                        epochs=20, batch_size = 32,\n",
    "                        callbacks=[early_stop],\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf44056",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss']);\n",
    "plt.plot(history.history['loss']);\n",
    "\n",
    "plt.legend(['val_loss','loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy']);\n",
    "plt.plot(history.history['accuracy']);\n",
    "\n",
    "plt.legend(['val_accuracy','accuracy']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef5157",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the LSTM model\n",
    "lstm_model = Sequential([\n",
    "    keras.layers.Embedding(input_dim = 10000, output_dim = 128),\n",
    "    LSTM(512, return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    LSTM(256, return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    LSTM(128, return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = lstm_model.fit(X_train, y_train, epochs=30, batch_size=32, callbacks=[early_stop], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss']);\n",
    "plt.plot(history.history['loss']);\n",
    "\n",
    "plt.legend(['val_loss','loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef61c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy']);\n",
    "plt.plot(history.history['accuracy']);\n",
    "\n",
    "plt.legend(['val_accuracy','accuracy']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e6237",
   "metadata": {},
   "source": [
    "## Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1990e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import regex as re\n",
    "from tensorflow import keras\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d81d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Atharva\\Desktop\\rxib\\NLP codebasics\\movies_sentiment_data.csv\")\n",
    "display(df.head(1))\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = np.where(df['sentiment']=='positive',1,0)\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = spacy.load('en_core_web_sm')\n",
    "def clean_reviews(text):\n",
    "    # Remove HTML tags from the text using BeautifulSoup\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    \n",
    "    # Remove URLs (starting with http, https, or www) from the text\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses (anything that starts with '@') from the text\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters (anything other than letters, numbers, and spaces) from the text\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove any digits from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove stop words from the text (words that are common and provide little meaning)\n",
    "    # 'sw' is a predefined list of stop words\n",
    "    text = ' '.join([word for word in text.split() if word not in sw])\n",
    "    \n",
    "    # Apply stemming to reduce words to their root form (using a stemmer like PorterStemmer)\n",
    "    # 'stemmer' is a predefined stemmer object\n",
    "#     doc = spacy.load('en_core_web_sm')\n",
    "    text = doc(text)\n",
    "    text = \" \".join([token.lemma_ for token in text])\n",
    "#     text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    # Remove extra spaces (more than one space) and strip leading/trailing spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_reviews'] = df['review'].apply(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, max_length = 128):\n",
    "    tokenized_text = tokenizer(text, padding = 'max_length', truncation=True, return_tensors = 'tf',max_length=max_length)\n",
    "    return tokenized_text['input_ids'], tokenized_text['token_type_ids'],tokenized_text['attention_mask']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de07f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, token_type_ids, attention_masks = [],  [], [] \n",
    "\n",
    "for text in df['cleaned_reviews']:\n",
    "    input_ids.append(tokenize(text)[0])\n",
    "    token_type_ids.append(tokenize(text)[1])\n",
    "    attention_masks.append(tokenize(text)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.squeeze(tf.convert_to_tensor(input_ids), axis=1)\n",
    "token_type_ids = tf.squeeze(tf.convert_to_tensor(token_type_ids), axis=1)\n",
    "attention_masks = tf.squeeze(tf.convert_to_tensor(attention_masks), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from inputs and labels\n",
    "labels = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202df442",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': input_ids,\n",
    "    'token_type_ids': token_type_ids,\n",
    "    'attention_mask': attention_masks\n",
    "}, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f11b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and batch the dataset\n",
    "train_dataset = train_dataset.shuffle(10000).batch(16)  # Adjust batch size as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom BERT classifier\n",
    "class BERTForClassification(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, bert_model):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = self.bert(inputs)\n",
    "        pooled_output = outputs[1]\n",
    "        return self.fc(pooled_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BERTForClassification(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = classifier.fit(\n",
    "    train_dataset,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f23d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
